{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from array import *\n",
    "from PIL import Image, ImageOps\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import linalg as lg\n",
    "from skimage.util import *\n",
    "from skimage.metrics import *\n",
    "from skimage.filters import laplace, sobel, roberts\n",
    "from skimage import color, data, measure\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import image\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins import projector\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, Layer, Activation, UpSampling2D,  \\\n",
    "    BatchNormalization, MaxPooling2D, Conv2DTranspose, Reshape, BatchNormalization, ReLU, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import activations, callbacks\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "from os.path import isfile, join, exists\n",
    "import re\n",
    "import joblib\n",
    "import glob\n",
    "import json\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "sys.path.append('..\\\\..\\\\..\\\\utils')\n",
    "from utils import *\n",
    "from autoencoder_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f4120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "constants_dictionary = json.load(open(\"..\\\\..\\\\..\\\\utils\\\\constants.json\",\"r\"))\n",
    "VALID_NOISE_STRENGHTS = constants_dictionary.get('VALID_NOISE_STRENGHTS')\n",
    "VALID_NOISE_TYPES = constants_dictionary.get('VALID_NOISE_TYPES') \n",
    "noise_dictionary = constants_dictionary.get('noise_dictionary')\n",
    "noise_levels_dictionary = constants_dictionary.get('noise_levels_dictionary')\n",
    "categorical_classes_dictionary = constants_dictionary.get('categorical_classes_dictionary')\n",
    "base_name = constants_dictionary.get('base_name_dae_images')\n",
    "mypath = constants_dictionary.get('path_images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e8ef9c",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder Grayscale for images 256x256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ecb59",
   "metadata": {},
   "source": [
    "## Grayscale images of size 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoising Autoencoder Grayscale\n",
    "\n",
    "images_size_256= 256\n",
    "x_256, y_256, y_noise_info_256 = get_ds_from_pkl(base_name, resize_images_to=images_size_256)\n",
    "\n",
    "X_train_256, X_test_256, y_train_256, y_test_256 = train_test_split(\n",
    "    x_256, \n",
    "    y_256, \n",
    "    test_size=0.15, \n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "d4_train_256 = X_train_256.reshape((X_train_256.shape[0], X_train_256.shape[1], X_train_256.shape[2], 1))\n",
    "d4_test_256=X_test_256.reshape((X_test_256.shape[0], X_test_256.shape[1], X_test_256.shape[2], 1))\n",
    "print('shape of training datset: ', d4_train_256.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7794ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dae_grayscale = load_model('..\\\\..\\\\..\\\\checkpoints\\\\Denoising_Autoencoder_grayscale.h5')\n",
    "except:\n",
    "    dae_grayscale = create_model('Denoising_Autoencoder_grayscale')\n",
    "    dae_grayscale.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    dae_grayscale.summary()\n",
    "    checkpoint = ModelCheckpoint('..\\\\..\\\\..\\\\checkpoints\\\\Denoising_Autoencoder_grayscale.h5', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    history = dae_grayscale.fit(d4_train_256, y_train_256, batch_size=4, epochs=50, callbacks=checkpoint, validation_split=0.25, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f6b97b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5d54c4",
   "metadata": {},
   "source": [
    "### PSNR and blurrines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_psnr_blur(d4_train_256,y_train_256,dae_grayscale)\n",
    "evaluate_psnr_blur(d4_test_256, y_test_256, dae_grayscale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f68dc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate each level of noise (levels from 1-8) and each category of noise level (low/medium/high)\n",
    "for var in noise_levels_dictionary.keys() + noise_dictionary.keys():\n",
    "    evaluate_image('gaussian', var, dae_grayscale)\n",
    "    evaluate_image('s&p', var, dae_grayscale)    \n",
    "    evaluate_image('speckle', var, dae_grayscale)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac04a555",
   "metadata": {},
   "source": [
    "###  execution ime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e35ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "x_test, y_test, y_ground_truth = get_single_noisy_image('gaussian', 'level5')\n",
    "prediction = dae_grayscale.predict(np.expand_dims((x_test), axis=0))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Execution time:', elapsed_time, 'seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc56ddd2",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a8829",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch_X = np.reshape(d4_dae_noise_test_dataset_gr_64, (d4_dae_noise_test_dataset_gr_64.shape[0], 64*64))\n",
    "gridSearch_Y = np.reshape(y_dae_noise_test_gray_64, (y_dae_noise_test_gray_64.shape[0], 64*64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeea6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [2, 4, 8, 16, 32]\n",
    "epochs = [10, 40, 60, 100]\n",
    "lr =  [0.0001, 0.001]\n",
    "opt = [\"adam\", \"sgd\"]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs,optimizer__learning_rate=lr, optimizer=opt)\n",
    "model = KerasRegressor(model=dae, verbose=0)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(gridSearch_X, gridSearch_Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30bcde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22dae66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad28a10e",
   "metadata": {},
   "source": [
    "## Grayscale images of size 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size_512= 512\n",
    "x_512, y_512, y_noise_info_512 = get_ds_from_pkl(base_name, resize_images_to=images_size_512)\n",
    "\n",
    "X_train_512, X_test_512, y_train_512, y_test_512 = train_test_split(\n",
    "    x_512, \n",
    "    y_512, \n",
    "    test_size=0.15, \n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "d4_train_512 = X_train_512.reshape((X_train_512.shape[0], X_train_512.shape[1], X_train_512.shape[2], 1))\n",
    "d4_test_512=X_test_512.reshape((X_test_512.shape[0], X_test_512.shape[1], X_test_512.shape[2], 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3025b",
   "metadata": {},
   "source": [
    "## Grayscale images of size 64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e264e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_size_64=64\n",
    "load_mixed_ds_to_pkl(resize_to=images_size_64)\n",
    "x_64, y_64, y_noise_info_64 = get_ds_from_pkl(base_name, resize_images_to=images_size_64)\n",
    "\n",
    "X_train_64, X_test_64, y_train_64, y_test_64 = train_test_split(\n",
    "    x_64, \n",
    "    y_64, \n",
    "    test_size=0.15, \n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "d4_train_64 = X_train_64.reshape((X_train_64.shape[0], X_train_64.shape[1], X_train_64.shape[2], 1))\n",
    "d4_test_64=X_test_64.reshape((X_test_64.shape[0], X_test_64.shape[1], X_test_64.shape[2], 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad5d96",
   "metadata": {},
   "source": [
    "# Denoising Autoencoder Grayscale for images with arbitrary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ffdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/developershutt/Autoencoders/blcob/main/3%20-%20Denoise%20Autoencoder/Code.ipynb\n",
    "\n",
    "# Encoder\n",
    "encoder_input = Input(shape=(None,None,1))\n",
    "x1 = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_input)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPool2D(pool_size = (2,2), padding='same')(x1)\n",
    "x2 = Conv2D(64, (3,3), activation='relu', padding='same')(x1)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPool2D(pool_size = (2,2), padding='same')(x2)\n",
    "x3 = Conv2D(32, (3,3), activation='relu', padding='same')(x2)\n",
    "x3 = BatchNormalization()(x3)\n",
    "encoded = MaxPool2D(pool_size = (2,2), padding='same')(x3)\n",
    "\n",
    "\n",
    "# Decoder\n",
    "x3 = Conv2D(32, (3,3), activation='relu', padding='same')(encoded)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = UpSampling2D((2,2))(x3)\n",
    "x2 = Conv2D(64, (3,3), activation='relu', padding='same')(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = UpSampling2D((2,2))(x2)\n",
    "x1 = Conv2D(128, (3,3), activation='relu', padding='same')(x2)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = UpSampling2D((2,2))(x1)\n",
    "decoded = Conv2D(1, (3,3), activation='sigmoid', padding= 'same')(x1)\n",
    "\n",
    "dae_simple = Model(encoder_input, decoded, name = 'Denoising_Autoencoder_grayscale_uniform')\n",
    "dae_simple.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "dae_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec79d283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    checkpoint = ModelCheckpoint('Denoising_Autoencoder_grayscale_uniform.h5', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    history = dae_simple.fit(d4_train_512, train_gray_512_y, batch_size=1, epochs=40, callbacks=checkpoint, validation_split=0.25, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5e4d3",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e59d1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dae_grayscale = load_model('Denoising_Autoencoder_grayscale_uniform.h5')\n",
    "dae_grayscale.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4debed",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_data(d4_train_64[20:23], 1,3)\n",
    "visualize_data(d4_train_64[20:23], 1,3)\n",
    "prediction_gray = dae_grayscale.predict(d4_train_64[20:23], batch_size=1)\n",
    "visualize_data(prediction_gray, 1,3)\n",
    "\n",
    "evaluate_psnr_blur(d4_train_64,y_train_512,dae_grayscale)\n",
    "evaluate_psnr_blur(d4_test_512, y_test_512, dae_grayscale)\n",
    "\n",
    "for var in noise_levels_dictionary.keys():\n",
    "    evaluate_image('gaussian', var, dae_grayscale)\n",
    "    evaluate_image('s&p', var, dae_grayscale)    \n",
    "    evaluate_image('speckle', var, dae_grayscale)   \n",
    "    \n",
    "# evaluate each category of noise level (low/medium/high)\n",
    "for var in noise_dictionary.keys():\n",
    "    evaluate_image('gaussian', var, dae_grayscale)\n",
    "    evaluate_image('s&p', var, dae_grayscale)    \n",
    "    evaluate_image('speckle', var, dae_grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a1557",
   "metadata": {},
   "source": [
    "# DENOISING AUTOENCODER RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ac414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "\n",
    "encoder_input = Input(shape=(None,None,3))\n",
    "x1 = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_input)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPool2D(pool_size = (2,2), padding='same')(x1)\n",
    "x2 = Conv2D(64, (3,3), activation='relu', padding='same')(x1)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPool2D(pool_size = (2,2), padding='same')(x2)\n",
    "x3 = Conv2D(32, (3,3), activation='relu', padding='same')(x2)\n",
    "x3 = BatchNormalization()(x3)\n",
    "encoded = MaxPool2D(pool_size = (2,2), padding='same')(x3)\n",
    "\n",
    "\n",
    "# Decoder\n",
    "x3 = Conv2D(32, (3,3), activation='relu', padding='same')(encoded)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = UpSampling2D((2,2))(x3)\n",
    "x2 = Conv2D(64, (3,3), activation='relu', padding='same')(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = UpSampling2D((2,2))(x2)\n",
    "x1 = Conv2D(128, (3,3), activation='relu', padding='same')(x2)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = UpSampling2D((2,2))(x1)\n",
    "decoded = Conv2D(3, (3,3), activation='sigmoid', padding= 'same')(x1)\n",
    "\n",
    "dae_rgb = Model(encoder_input, decoded, name = 'Denoising_Autoencoder_rgb')\n",
    "dae_rgb.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "dae_rgb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3479f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    checkpoint = ModelCheckpoint('Denoising_Autoencoder_rgb.h5', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    history = dae_rgb.fit(d4_rgb_256_train_dataset, y_rgb_256_train, batch_size=1, epochs=40, callbacks=checkpoint, validation_split=0.25, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dae_rgb = load_model('Denoising_Autoencoder_rgb.h5')\n",
    "dae_rgb.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f555c2b",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edebedff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "\n",
    "visualize_data(d4_rgb_256_test_dataset[:3], 1,3, mode='rgb')\n",
    "pred_test_rgb_256 = dae_rgb.predict(d4_rgb_256_test_dataset[:3], batch_size=1)\n",
    "visualize_data(pred_test_rgb_256, 1, 3, mode='rgb')\n",
    "visualize_data(y_rgb_256_test[:3], 1, 3, mode='rgb')\n",
    "\n",
    "evaluate_psnr_blur(d4_train_256_rgb,y_train_256_rgb,dae_rgb)\n",
    "evaluate_psnr_blur(d4_rgb_256_test_dataset, y_rgb_256_test, dae_rgb)\n",
    "\n",
    "for var in noise_levels_dictionary.keys():\n",
    "    evaluate_image('gaussian', var, dae_rgb)\n",
    "    evaluate_image('s&p', var, dae_rgb)    \n",
    "    evaluate_image('speckle', var, dae_rgb)   \n",
    "    \n",
    "# evaluate each category of noise level (low/medium/high)\n",
    "for var in noise_dictionary.keys():\n",
    "    evaluate_image('gaussian', var, dae_rgb)\n",
    "    evaluate_image('s&p', var, dae_rgb)    \n",
    "    evaluate_image('speckle', var, dae_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d608357",
   "metadata": {},
   "source": [
    "#  RGB images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93820d26",
   "metadata": {},
   "source": [
    "## load 512 & 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970bb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_512, y_512, y_noise_info_512 = get_ds_from_pkl(base_name, resize_images_to=images_size_512, mode='rgb')\n",
    "\n",
    "X_train_512_rgb, X_test_512_rgb, y_train_512_rgb, y_test_512_rgb = train_test_split(\n",
    "    x_512, \n",
    "    y_512, \n",
    "    test_size=0.15, \n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "d4_train_512_rgb = X_train_512_rgb.reshape((X_train_512_rgb.shape[0], X_train_512_rgb.shape[1], X_train_512_rgb.shape[2], 1))\n",
    "d4_test_512_rgb=X_test_512_rgb.reshape((X_test_512_rgb.shape[0], X_test_512_rgb.shape[1], X_test_512_rgb.shape[2], 1))\n",
    "\n",
    "x_256, y_256, y_noise_info_256 = get_ds_from_pkl(base_name, resize_images_to=images_size_256, mode='rgb')\n",
    "\n",
    "X_train_256_rgb, X_test_256_rgb, y_train_256_rgb, y_test_256_rgb = train_test_split(\n",
    "    x_256, \n",
    "    y_256, \n",
    "    test_size=0.15, \n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "d4_train_256_rgb = X_train_256_rgb.reshape((X_train_256_rgb.shape[0], X_train_256_rgb.shape[1], X_train_256_rgb.shape[2], 1))\n",
    "d4_test_256_rgb=X_test_256_rgb.reshape((X_test_256_rgb.shape[0], X_test_256_rgb.shape[1], X_test_256_rgb.shape[2], 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
